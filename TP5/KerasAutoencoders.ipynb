{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDMaoeL5lfsq"
      },
      "source": [
        "# Generación por Autoencoders\n",
        "\n",
        "Este ejemplo buenísimo muestra como se puede usar la información del espacio latente de los autoencoders para interpolar nuevos ejemplos de los dígitos de códigos postales de MNIST.\n",
        "\n",
        "Está sacado del libro de Langr, \"GANs in action\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grno4di7hFBf",
        "outputId": "7dd4517a-0470-4de9-cecd-11e1d2217263"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.22.3\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "#!pip install numpy==1.19.5\n",
        "#!pip install tensorflow==2.2.0\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "#from tensorflow import keras\n",
        "### hack tf-keras to appear as top level keras\n",
        "#import sys\n",
        "#sys.modules['keras'] = keras\n",
        "### end of hack\n",
        "\n",
        "from keras.layers import Input, Dense, Lambda, Reshape\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras import metrics\n",
        "from keras.datasets import mnist\n",
        "\n",
        "from tensorflow.python.framework.ops import disable_eager_execution\n",
        "disable_eager_execution()\n",
        "\n",
        "\n",
        "\n",
        "print(np.__version__)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "6gylL5N2hPmv"
      },
      "outputs": [],
      "source": [
        "\n",
        "# defining the key parameters\n",
        "batch_size = 1\n",
        "\n",
        "# Parameters of the input images (handwritten digits)\n",
        "original_dim = 7*5\n",
        "\n",
        "# Latent space is of dimension 2.  This means that we are reducing the dimension from 784 to 2\n",
        "latent_dim = 2\n",
        "intermediate_dim = 10\n",
        "epochs = 2\n",
        "epsilon_std = 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp_GBGkMuWWo"
      },
      "source": [
        "La función de Sampling es la que toma la salida de la media y la varianza que estima el Encoder y la usa para generar una muestra que va a servir a estimar la pdf de los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "EaAVBVXmhTVI"
      },
      "outputs": [],
      "source": [
        "def sampling(args: tuple):\n",
        "    # we grab the variables from the tuple\n",
        "    z_mean, z_log_var = args\n",
        "    print(z_mean)\n",
        "    print(z_log_var)\n",
        "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0.,\n",
        "                              stddev=epsilon_std)\n",
        "    return z_mean + K.exp(z_log_var / 2) * epsilon  # h(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cGTlodOriZ-"
      },
      "source": [
        "# Codificador\n",
        "\n",
        "Esta primera parte define el codificador, es decir la primera red que baja la dimensionalidad de los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8J2tfwH7hben",
        "outputId": "7a39bb4c-b4ef-41d6-a2c6-8eb4c74834a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor(\"mean_15/BiasAdd:0\", shape=(None, 2), dtype=float32)\n",
            "Tensor(\"log-variance_15/BiasAdd:0\", shape=(None, 2), dtype=float32)\n",
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 35)]         0           []                               \n",
            "                                                                                                  \n",
            " encoding (Dense)               (None, 10)           360         ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " mean (Dense)                   (None, 2)            22          ['encoding[0][0]']               \n",
            "                                                                                                  \n",
            " log-variance (Dense)           (None, 2)            22          ['encoding[0][0]']               \n",
            "                                                                                                  \n",
            " lambda_15 (Lambda)             (None, 2)            0           ['mean[0][0]',                   \n",
            "                                                                  'log-variance[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 404\n",
            "Trainable params: 404\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# input to our encoder\n",
        "x = Input(shape=(original_dim,), name=\"input\")\n",
        "# intermediate layer\n",
        "h = Dense(intermediate_dim, activation='relu', name=\"encoding\")(x)\n",
        "# defining the mean of the latent space\n",
        "z_mean = Dense(latent_dim, name=\"mean\")(h)\n",
        "# defining the log variance of the latent space\n",
        "z_log_var = Dense(latent_dim, name=\"log-variance\")(h)\n",
        "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
        "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
        "# defining the encoder as a keras model\n",
        "encoder = Model(x, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "# print out summary of what we just did\n",
        "encoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW2bBFULsBSs"
      },
      "source": [
        "# Decodificador\n",
        "\n",
        "Esta segunda parte es la definición del decodificador, que es la segunda parte que decodifica la información del espacio latente hacia la salida final de las dos redes en serie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ev9fCeGRhqHp",
        "outputId": "176c6046-2c6d-4188-ba79-3f017ae29f35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 2)]               0         \n",
            "                                                                 \n",
            " decoder_h (Dense)           (None, 10)                30        \n",
            "                                                                 \n",
            " flat_decoded (Dense)        (None, 35)                385       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 415\n",
            "Trainable params: 415\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Input to the decoder\n",
        "input_decoder = Input(shape=(latent_dim,), name=\"decoder_input\")\n",
        "# taking the latent space to intermediate dimension\n",
        "decoder_h = Dense(intermediate_dim, activation='relu', name=\"decoder_h\")(input_decoder)\n",
        "# getting the mean from the original dimension\n",
        "x_decoded = Dense(original_dim, activation='sigmoid', name=\"flat_decoded\")(decoder_h)\n",
        "# defining the decoder as a keras model\n",
        "decoder = Model(input_decoder, x_decoded, name=\"decoder\")\n",
        "decoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuwZuVAbsLlr"
      },
      "source": [
        "# Autoencoder completo\n",
        "\n",
        "Se combinan las dos partes.  Primero el Codificador y luego del decodifcador.  Acá se muestra la información de cómo queda el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBUymccKhxdf",
        "outputId": "bb35b189-c486-43a3-8245-5c838c6f22f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor(\"encoder_15/mean/BiasAdd:0\", shape=(None, 2), dtype=float32)\n",
            "Tensor(\"encoder_15/log-variance/BiasAdd:0\", shape=(None, 2), dtype=float32)\n",
            "Model: \"model_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 35)]              0         \n",
            "                                                                 \n",
            " encoder (Functional)        [(None, 2),               404       \n",
            "                              (None, 2),                         \n",
            "                              (None, 2)]                         \n",
            "                                                                 \n",
            " decoder (Functional)        (None, 35)                415       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 819\n",
            "Trainable params: 819\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# grab the output. Recall, that we need to grab the 3rd element our sampling z\n",
        "output_combined = decoder(encoder(x)[2])\n",
        "# link the input and the overall output\n",
        "vae = Model(x, output_combined)\n",
        "# print out what the overall model looks like\n",
        "vae.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRcz7RhEsbx9"
      },
      "source": [
        "# Función de perdida\n",
        "\n",
        "Se define la función de perdida, y se establece cuál va a ser la función de optimización."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "CAm6NZ6Tf-LZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.datasets import mnist\n",
        "from keras import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aqpd08w-h6c_",
        "outputId": "1f63c3c7-0d56-45e4-dac0-8b3331377ccc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 35)]              0         \n",
            "                                                                 \n",
            " encoder (Functional)        [(None, 2),               404       \n",
            "                              (None, 2),                         \n",
            "                              (None, 2)]                         \n",
            "                                                                 \n",
            " decoder (Functional)        (None, 35)                415       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 819\n",
            "Trainable params: 819\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def vae_loss(x: tf.Tensor, x_decoded_mean: tf.Tensor):\n",
        "  # Aca se computa la cross entropy entre los \"labels\" x que son los valores 0/1 de los pixeles, y lo que salió al final del Decoder.\n",
        "  xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean) # x-^X\n",
        "  kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "  vae_loss = K.mean(xent_loss + kl_loss)\n",
        "  return vae_loss\n",
        "\n",
        "vae.compile( loss=vae_loss)\n",
        "vae.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHowf3udskDP"
      },
      "source": [
        "Se cargan los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvdIgDhjh_UO",
        "outputId": "e58b4881-fbf6-4919-8816-d83f27827e1d"
      },
      "outputs": [],
      "source": [
        "import fonts\n",
        "rng = np.random.RandomState(17)\n",
        "dataset = np.array([[x.flatten(), x.flatten()] for x in fonts.f1])\n",
        "dataset = dataset[0:5]\n",
        "noise = []\n",
        "iters = 100\n",
        "y_test = []\n",
        "y_train = []\n",
        "for i in range(iters):\n",
        "    for j, (IN,OUT) in enumerate(dataset):\n",
        "        IN += rng.normal(0, 1, IN.shape)\n",
        "        noise.append(IN)\n",
        "        y_train.append(OUT)\n",
        "        y_test.append(j)\n",
        "\n",
        "\n",
        "y_train = np.array([x.flatten() for x in y_train])\n",
        "x_train = np.array([x.flatten() for x in noise])\n",
        "x_test = np.array([x.flatten() for x in noise])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duTtPSmvsn3z"
      },
      "source": [
        "Se entrena finalmente la red de forma completa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Qm1emzwiCu0",
        "outputId": "4731e628-8264-43d2-f71b-880163402610"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 500 samples\n",
            "Epoch 1/2\n",
            "500/500 [==============================] - 2s 2ms/sample - loss: 79.8499\n",
            "Epoch 2/2\n",
            "500/500 [==============================] - 1s 2ms/sample - loss: 15.4782\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f105c788a00>"
            ]
          },
          "execution_count": 192,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vae.fit(x_train, y_train,\n",
        "        shuffle=True,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "M7KBqKG0lHpv",
        "outputId": "d9382af7-f5ad-4e65-8e45-1c6d25c901ec"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "x_test_encoded = encoder.predict(x_test, batch_size=1)[0]\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(x_test_encoded[:,0], x_test_encoded[:,1], c=y_test, cmap='viridis')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "vOOvIVeAlR1-",
        "outputId": "0b5436a8-f876-47b4-a8ad-248e0a28aaa8"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "cannot reshape array of size 35 into shape (25,25)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/home/natu/Itba/sia/TPs_SIA/TP5/KerasAutoencoders.ipynb Cell 20'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/natu/Itba/sia/TPs_SIA/TP5/KerasAutoencoders.ipynb#ch0000019?line=10'>11</a>\u001b[0m         z_sample \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[xi, yi]])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/natu/Itba/sia/TPs_SIA/TP5/KerasAutoencoders.ipynb#ch0000019?line=11'>12</a>\u001b[0m         x_decoded \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39mpredict(z_sample)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/natu/Itba/sia/TPs_SIA/TP5/KerasAutoencoders.ipynb#ch0000019?line=12'>13</a>\u001b[0m         digit \u001b[39m=\u001b[39m x_decoded[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mreshape(digit_size, digit_size)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/natu/Itba/sia/TPs_SIA/TP5/KerasAutoencoders.ipynb#ch0000019?line=13'>14</a>\u001b[0m         figure[i \u001b[39m*\u001b[39m digit_size: (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m digit_size,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/natu/Itba/sia/TPs_SIA/TP5/KerasAutoencoders.ipynb#ch0000019?line=14'>15</a>\u001b[0m                j \u001b[39m*\u001b[39m digit_size: (j \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m digit_size] \u001b[39m=\u001b[39m digit\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/natu/Itba/sia/TPs_SIA/TP5/KerasAutoencoders.ipynb#ch0000019?line=16'>17</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m, \u001b[39m10\u001b[39m))\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 35 into shape (25,25)"
          ]
        }
      ],
      "source": [
        "n = 15  # figure with 15x15 digits\n",
        "digit_size = 25\n",
        "figure = np.zeros((digit_size * n, digit_size * n))\n",
        "# linearly spaced coordinates on the unit square were transformed through the inverse CDF (ppf) of the Gaussian\n",
        "# to produce values of the latent variables z, since the prior of the latent space is Gaussian\n",
        "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "\n",
        "for i, yi in enumerate(grid_x):\n",
        "    for j, xi in enumerate(grid_y):\n",
        "        z_sample = np.array([[xi, yi]])\n",
        "        x_decoded = decoder.predict(z_sample)\n",
        "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "        figure[i * digit_size: (i + 1) * digit_size,\n",
        "               j * digit_size: (j + 1) * digit_size] = digit\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(figure, cmap='Greys_r')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MR9YyYG4ozla",
        "outputId": "57e46070-c4e1-458a-ba11-cdb65cd61ed1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-1.64485363e+00 -1.20404696e+00 -9.20822976e-01 -6.97141435e-01\n",
            " -5.03965367e-01 -3.28072108e-01 -1.61844167e-01 -1.39145821e-16\n",
            "  1.61844167e-01  3.28072108e-01  5.03965367e-01  6.97141435e-01\n",
            "  9.20822976e-01  1.20404696e+00  1.64485363e+00]\n"
          ]
        }
      ],
      "source": [
        "print(grid_x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPEZ780fpCgd",
        "outputId": "607f0ddb-f372-4727-bb72-ca02529d2ced"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.64485363 1.64485363]]\n"
          ]
        }
      ],
      "source": [
        "print(z_sample)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "KerasAutoencoders.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
