{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDMaoeL5lfsq"
      },
      "source": [
        "# Generación por Autoencoders\n",
        "\n",
        "Este ejemplo buenísimo muestra como se puede usar la información del espacio latente de los autoencoders para interpolar nuevos ejemplos de los dígitos de códigos postales de MNIST.\n",
        "\n",
        "Está sacado del libro de Langr, \"GANs in action\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grno4di7hFBf",
        "outputId": "7dd4517a-0470-4de9-cecd-11e1d2217263"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-19 17:23:02.070534: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2022-06-19 17:23:02.070588: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.22.3\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "#!pip install numpy==1.19.5\n",
        "#!pip install tensorflow==2.2.0\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "#from tensorflow import keras\n",
        "### hack tf-keras to appear as top level keras\n",
        "#import sys\n",
        "#sys.modules['keras'] = keras\n",
        "### end of hack\n",
        "\n",
        "from keras.layers import Input, Dense, Lambda, Reshape\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras import metrics\n",
        "from keras.datasets import mnist\n",
        "\n",
        "from tensorflow.python.framework.ops import disable_eager_execution\n",
        "disable_eager_execution()\n",
        "\n",
        "\n",
        "\n",
        "print(np.__version__)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6gylL5N2hPmv"
      },
      "outputs": [],
      "source": [
        "\n",
        "# defining the key parameters\n",
        "batch_size = 1\n",
        "\n",
        "# Parameters of the input images (handwritten digits)\n",
        "original_dim = 7*5\n",
        "\n",
        "# Latent space is of dimension 2.  This means that we are reducing the dimension from 784 to 2\n",
        "latent_dim = 2\n",
        "intermediate_dim = 15\n",
        "epochs = 50\n",
        "epsilon_std = 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp_GBGkMuWWo"
      },
      "source": [
        "La función de Sampling es la que toma la salida de la media y la varianza que estima el Encoder y la usa para generar una muestra que va a servir a estimar la pdf de los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EaAVBVXmhTVI"
      },
      "outputs": [],
      "source": [
        "def sampling(args: tuple):\n",
        "    # we grab the variables from the tuple\n",
        "    z_mean, z_log_var = args\n",
        "    print(z_mean)\n",
        "    print(z_log_var)\n",
        "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0.,\n",
        "                              stddev=epsilon_std)\n",
        "    return z_mean + K.exp(z_log_var / 2) * epsilon  # h(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cGTlodOriZ-"
      },
      "source": [
        "# Codificador\n",
        "\n",
        "Esta primera parte define el codificador, es decir la primera red que baja la dimensionalidad de los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8J2tfwH7hben",
        "outputId": "7a39bb4c-b4ef-41d6-a2c6-8eb4c74834a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor(\"mean/BiasAdd:0\", shape=(None, 2), dtype=float32)\n",
            "Tensor(\"log-variance/BiasAdd:0\", shape=(None, 2), dtype=float32)\n",
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 35)]         0           []                               \n",
            "                                                                                                  \n",
            " encoding (Dense)               (None, 15)           540         ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " mean (Dense)                   (None, 2)            32          ['encoding[0][0]']               \n",
            "                                                                                                  \n",
            " log-variance (Dense)           (None, 2)            32          ['encoding[0][0]']               \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 2)            0           ['mean[0][0]',                   \n",
            "                                                                  'log-variance[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 604\n",
            "Trainable params: 604\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# input to our encoder\n",
        "x = Input(shape=(original_dim,), name=\"input\")\n",
        "# intermediate layer\n",
        "h = Dense(intermediate_dim, activation='relu', name=\"encoding\")(x)\n",
        "# defining the mean of the latent space\n",
        "z_mean = Dense(latent_dim, name=\"mean\")(h)\n",
        "# defining the log variance of the latent space\n",
        "z_log_var = Dense(latent_dim, name=\"log-variance\")(h)\n",
        "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
        "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
        "# defining the encoder as a keras model\n",
        "encoder = Model(x, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "# print out summary of what we just did\n",
        "encoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW2bBFULsBSs"
      },
      "source": [
        "# Decodificador\n",
        "\n",
        "Esta segunda parte es la definición del decodificador, que es la segunda parte que decodifica la información del espacio latente hacia la salida final de las dos redes en serie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ev9fCeGRhqHp",
        "outputId": "176c6046-2c6d-4188-ba79-3f017ae29f35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 2)]               0         \n",
            "                                                                 \n",
            " decoder_h (Dense)           (None, 15)                45        \n",
            "                                                                 \n",
            " flat_decoded (Dense)        (None, 35)                560       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 605\n",
            "Trainable params: 605\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Input to the decoder\n",
        "input_decoder = Input(shape=(latent_dim,), name=\"decoder_input\")\n",
        "# taking the latent space to intermediate dimension\n",
        "decoder_h = Dense(intermediate_dim, activation='relu', name=\"decoder_h\")(input_decoder)\n",
        "# getting the mean from the original dimension\n",
        "x_decoded = Dense(original_dim, activation='sigmoid', name=\"flat_decoded\")(decoder_h)\n",
        "# defining the decoder as a keras model\n",
        "decoder = Model(input_decoder, x_decoded, name=\"decoder\")\n",
        "decoder.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuwZuVAbsLlr"
      },
      "source": [
        "# Autoencoder completo\n",
        "\n",
        "Se combinan las dos partes.  Primero el Codificador y luego del decodifcador.  Acá se muestra la información de cómo queda el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBUymccKhxdf",
        "outputId": "bb35b189-c486-43a3-8245-5c838c6f22f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor(\"encoder/mean/BiasAdd:0\", shape=(None, 2), dtype=float32)\n",
            "Tensor(\"encoder/log-variance/BiasAdd:0\", shape=(None, 2), dtype=float32)\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 35)]              0         \n",
            "                                                                 \n",
            " encoder (Functional)        [(None, 2),               604       \n",
            "                              (None, 2),                         \n",
            "                              (None, 2)]                         \n",
            "                                                                 \n",
            " decoder (Functional)        (None, 35)                605       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,209\n",
            "Trainable params: 1,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# grab the output. Recall, that we need to grab the 3rd element our sampling z\n",
        "output_combined = decoder(encoder(x)[2])\n",
        "# link the input and the overall output\n",
        "vae = Model(x, output_combined)\n",
        "# print out what the overall model looks like\n",
        "vae.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRcz7RhEsbx9"
      },
      "source": [
        "# Función de perdida\n",
        "\n",
        "Se define la función de perdida, y se establece cuál va a ser la función de optimización."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CAm6NZ6Tf-LZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.datasets import mnist\n",
        "from keras import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aqpd08w-h6c_",
        "outputId": "1f63c3c7-0d56-45e4-dac0-8b3331377ccc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 35)]              0         \n",
            "                                                                 \n",
            " encoder (Functional)        [(None, 2),               604       \n",
            "                              (None, 2),                         \n",
            "                              (None, 2)]                         \n",
            "                                                                 \n",
            " decoder (Functional)        (None, 35)                605       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,209\n",
            "Trainable params: 1,209\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def vae_loss(x: tf.Tensor, x_decoded_mean: tf.Tensor):\n",
        "  # Aca se computa la cross entropy entre los \"labels\" x que son los valores 0/1 de los pixeles, y lo que salió al final del Decoder.\n",
        "  xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean) # x-^X\n",
        "  kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
        "  vae_loss = K.mean(xent_loss + kl_loss)\n",
        "  return vae_loss\n",
        "\n",
        "vae.compile( loss=vae_loss)\n",
        "vae.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHowf3udskDP"
      },
      "source": [
        "Se cargan los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvdIgDhjh_UO",
        "outputId": "e58b4881-fbf6-4919-8816-d83f27827e1d"
      },
      "outputs": [],
      "source": [
        "import fonts\n",
        "x_train = np.array([x.flatten() for x in fonts.f2])\n",
        "y_train =np.array([x.flatten() for x in fonts.f2])\n",
        "x_test = np.array([x.flatten() for x in fonts.f2])\n",
        "y_test =np.array([x.flatten() for x in fonts.f2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duTtPSmvsn3z"
      },
      "source": [
        "Se entrena finalmente la red de forma completa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Qm1emzwiCu0",
        "outputId": "4731e628-8264-43d2-f71b-880163402610"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 32 samples\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-06-19 17:24:29.010124: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
            "2022-06-19 17:24:29.010160: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2022-06-19 17:24:29.010184: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (natu-linux): /proc/driver/nvidia/version does not exist\n",
            "2022-06-19 17:24:29.065987: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-06-19 17:24:29.215023: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 3s 1ms/sample - loss: 24.6197\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 23.9267\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 23.7826\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 23.4502\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 23.1212\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 22.9646\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 23.0848\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 3ms/sample - loss: 22.4500\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 22.4529\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 22.3361\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 22.1077\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 21.9200\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 22.2032\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 21.8171\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 21.8199\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 21.6403\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 21.2120\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 21.5748\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 21.6469\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 21.3562\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 21.4937\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 20.8504\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 20.8951\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 21.0210\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 20.4533\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 20.8601\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 20.9110\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 20.8065\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 20.8956\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 20.6768\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 20.5883\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 20.8563\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 20.5305\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 20.1714\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 20.2024\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 20.6400\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 20.8579\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 20.2668\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 20.7876\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 20.5095\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 20.5508\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 20.1937\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 20.0588\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 20.5694\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 20.3363\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 19.5337\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 19.8028\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 20.4034\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 1ms/sample - loss: 20.2093\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 2ms/sample - loss: 20.1212\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f44d2d1cac0>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vae.fit(x_train, x_train,\n",
        "        shuffle=True,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "M7KBqKG0lHpv",
        "outputId": "d9382af7-f5ad-4e65-8e45-1c6d25c901ec"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)[0]\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(x_test_encoded[:,0], x_test_encoded[:,1], cmap='viridis')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "vOOvIVeAlR1-",
        "outputId": "0b5436a8-f876-47b4-a8ad-248e0a28aaa8"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "cannot reshape array of size 35 into shape (28,28)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/home/natu/Itba/sia/TPs_SIA/TP5/KerasAutoencoders.ipynb Cell 20'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/natu/Itba/sia/TPs_SIA/TP5/KerasAutoencoders.ipynb#ch0000019?line=10'>11</a>\u001b[0m         z_sample \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([[xi, yi]])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/natu/Itba/sia/TPs_SIA/TP5/KerasAutoencoders.ipynb#ch0000019?line=11'>12</a>\u001b[0m         x_decoded \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39mpredict(z_sample)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/natu/Itba/sia/TPs_SIA/TP5/KerasAutoencoders.ipynb#ch0000019?line=12'>13</a>\u001b[0m         digit \u001b[39m=\u001b[39m x_decoded[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mreshape(digit_size, digit_size)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/natu/Itba/sia/TPs_SIA/TP5/KerasAutoencoders.ipynb#ch0000019?line=13'>14</a>\u001b[0m         figure[i \u001b[39m*\u001b[39m digit_size: (i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m digit_size,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/natu/Itba/sia/TPs_SIA/TP5/KerasAutoencoders.ipynb#ch0000019?line=14'>15</a>\u001b[0m                j \u001b[39m*\u001b[39m digit_size: (j \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m digit_size] \u001b[39m=\u001b[39m digit\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/natu/Itba/sia/TPs_SIA/TP5/KerasAutoencoders.ipynb#ch0000019?line=16'>17</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m, \u001b[39m10\u001b[39m))\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 35 into shape (28,28)"
          ]
        }
      ],
      "source": [
        "n = 15  # figure with 15x15 digits\n",
        "digit_size = 28\n",
        "figure = np.zeros((digit_size * n, digit_size * n))\n",
        "# linearly spaced coordinates on the unit square were transformed through the inverse CDF (ppf) of the Gaussian\n",
        "# to produce values of the latent variables z, since the prior of the latent space is Gaussian\n",
        "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "\n",
        "for i, yi in enumerate(grid_x):\n",
        "    for j, xi in enumerate(grid_y):\n",
        "        z_sample = np.array([[xi, yi]])\n",
        "        x_decoded = decoder.predict(z_sample)\n",
        "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "        figure[i * digit_size: (i + 1) * digit_size,\n",
        "               j * digit_size: (j + 1) * digit_size] = digit\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(figure, cmap='Greys_r')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MR9YyYG4ozla",
        "outputId": "57e46070-c4e1-458a-ba11-cdb65cd61ed1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-1.64485363e+00 -1.20404696e+00 -9.20822976e-01 -6.97141435e-01\n",
            " -5.03965367e-01 -3.28072108e-01 -1.61844167e-01 -1.39145821e-16\n",
            "  1.61844167e-01  3.28072108e-01  5.03965367e-01  6.97141435e-01\n",
            "  9.20822976e-01  1.20404696e+00  1.64485363e+00]\n"
          ]
        }
      ],
      "source": [
        "print(grid_x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPEZ780fpCgd",
        "outputId": "607f0ddb-f372-4727-bb72-ca02529d2ced"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.64485363 1.64485363]]\n"
          ]
        }
      ],
      "source": [
        "print(z_sample)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "KerasAutoencoders.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
